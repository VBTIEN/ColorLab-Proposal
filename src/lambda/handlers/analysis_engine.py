"""
Analysis Engine - Comprehensive image analysis with professional standards
"""
import boto3
import json
from .low_level_features import LowLevelFeatureExtractor
from .high_level_features import HighLevelFeatureExtractor
from .quality_metrics import QualityMetricsCalculator

class AnalysisEngine:
    def __init__(self):
        self.rekognition = boto3.client('rekognition')
        self.bedrock = boto3.client('bedrock-runtime')
        
        # Feature extractors
        self.low_level_extractor = LowLevelFeatureExtractor()
        self.high_level_extractor = HighLevelFeatureExtractor(self.rekognition)
        self.quality_calculator = QualityMetricsCalculator()
    
    def analyze_image(self, bucket, key):
        """Comprehensive image analysis following professional standards"""
        
        analysis_results = {
            'low_level_features': {},
            'high_level_features': {},
            'quality_metrics': {},
            'ai_analysis': {}
        }
        
        try:
            # 1. Low-level features (Color, Texture, Shape, Spatial)
            analysis_results['low_level_features'] = self.low_level_extractor.extract_features(bucket, key)
            
            # 2. High-level features (Deep features, Object detection, Segmentation)
            analysis_results['high_level_features'] = self.high_level_extractor.extract_features(bucket, key)
            
            # 3. Quality metrics (PSNR, SSIM, BRISQUE, etc.)
            analysis_results['quality_metrics'] = self.quality_calculator.calculate_metrics(bucket, key)
            
            # 4. AI-powered analysis (Bedrock)
            analysis_results['ai_analysis'] = self._get_ai_analysis(analysis_results)
            
        except Exception as e:
            print(f"Analysis Engine Error: {str(e)}")
            analysis_results['error'] = str(e)
        
        return analysis_results
    
    def _get_ai_analysis(self, features):
        """Get AI-powered analysis using Bedrock"""
        try:
            prompt = self._create_comprehensive_prompt(features)
            
            # Try multiple models
            models = [
                'anthropic.claude-3-haiku-20240307-v1:0',
                'anthropic.claude-v2:1'
            ]
            
            for model_id in models:
                try:
                    if 'claude-3' in model_id:
                        response = self.bedrock.invoke_model(
                            modelId=model_id,
                            body=json.dumps({
                                'anthropic_version': 'bedrock-2023-05-31',
                                'max_tokens': 2000,
                                'messages': [{
                                    'role': 'user',
                                    'content': prompt
                                }]
                            })
                        )
                        
                        response_body = json.loads(response['body'].read())
                        analysis = response_body['content'][0]['text']
                    else:
                        response = self.bedrock.invoke_model(
                            modelId=model_id,
                            body=json.dumps({
                                'prompt': f"\n\nHuman: {prompt}\n\nAssistant:",
                                'max_tokens_to_sample': 2000,
                                'temperature': 0.7
                            })
                        )
                        
                        response_body = json.loads(response['body'].read())
                        analysis = response_body['completion']
                    
                    return {
                        'professional_analysis': analysis.strip(),
                        'model_used': model_id,
                        'analysis_framework': 'comprehensive_professional'
                    }
                    
                except Exception as model_error:
                    print(f"Model {model_id} failed: {str(model_error)}")
                    continue
            
            # Fallback analysis
            return self._generate_professional_fallback(features)
            
        except Exception as e:
            print(f"AI Analysis error: {str(e)}")
            return self._generate_professional_fallback(features)
    
    def _create_comprehensive_prompt(self, features):
        """Create comprehensive analysis prompt based on extracted features"""
        
        low_level = features.get('low_level_features', {})
        high_level = features.get('high_level_features', {})
        quality = features.get('quality_metrics', {})
        
        prompt = f"""
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ·∫£nh chuy√™n nghi·ªáp. H√£y ph√¢n t√≠ch b·ª©c ·∫£nh d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng k·ªπ thu·∫≠t sau:

        üé® ƒê·∫∂C TR∆ØNG C∆† B·∫¢N (Low-level Features):
        - M√†u s·∫Øc: {low_level.get('color_analysis', 'N/A')}
        - K·∫øt c·∫•u: {low_level.get('texture_analysis', 'N/A')}
        - H√¨nh d·∫°ng: {low_level.get('shape_analysis', 'N/A')}
        - Kh√¥ng gian: {low_level.get('spatial_features', 'N/A')}

        üîç ƒê·∫∂C TR∆ØNG N√ÇNG CAO (High-level Features):
        - ƒê·ªëi t∆∞·ª£ng: {high_level.get('objects', 'N/A')}
        - Khu√¥n m·∫∑t: {high_level.get('faces', 'N/A')}
        - VƒÉn b·∫£n: {high_level.get('text', 'N/A')}
        - Ph√¢n ƒëo·∫°n: {high_level.get('segmentation', 'N/A')}

        üìä CH·∫§T L∆Ø·ª¢NG H√åNH ·∫¢NH:
        - ƒê·ªô s·∫Øc n√©t: {quality.get('sharpness', 'N/A')}
        - ƒê·ªô t∆∞∆°ng ph·∫£n: {quality.get('contrast', 'N/A')}
        - ƒê·ªô s√°ng: {quality.get('brightness', 'N/A')}
        - Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng: {quality.get('quality_score', 'N/A')}

        üìù Y√äU C·∫¶U PH√ÇN T√çCH CHUY√äN NGHI·ªÜP:
        1. ƒê√°nh gi√° k·ªπ thu·∫≠t (Technical Assessment)
        2. Ph√¢n t√≠ch composition v√† th·∫©m m·ªπ (Aesthetic Analysis)
        3. Ch·∫•t l∆∞·ª£ng h√¨nh ·∫£nh (Image Quality)
        4. ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t (Key Features)
        5. G·ª£i √Ω c·∫£i thi·ªán chuy√™n nghi·ªáp (Professional Recommendations)
        6. ·ª®ng d·ª•ng th·ª±c t·∫ø (Practical Applications)

        Vi·∫øt ph√¢n t√≠ch 6-8 c√¢u, chuy√™n nghi·ªáp nh∆∞ng d·ªÖ hi·ªÉu, b·∫±ng ti·∫øng Vi·ªát.
        """
        
        return prompt
    
    def _generate_professional_fallback(self, features):
        """Generate professional fallback analysis"""
        
        low_level = features.get('low_level_features', {})
        high_level = features.get('high_level_features', {})
        quality = features.get('quality_metrics', {})
        
        analysis_parts = []
        
        # Technical assessment
        if quality.get('sharpness'):
            sharpness = quality['sharpness']
            if sharpness > 80:
                analysis_parts.append("·∫¢nh c√≥ ƒë·ªô s·∫Øc n√©t cao, chi ti·∫øt r√µ r√†ng")
            elif sharpness > 60:
                analysis_parts.append("ƒê·ªô s·∫Øc n√©t ·ªü m·ª©c trung b√¨nh")
            else:
                analysis_parts.append("C·∫ßn c·∫£i thi·ªán ƒë·ªô s·∫Øc n√©t")
        
        # Color analysis
        if low_level.get('color_analysis'):
            color_info = low_level['color_analysis']
            dominant_colors = color_info.get('dominant_colors', [])
            if len(dominant_colors) > 3:
                analysis_parts.append("v·ªõi b·∫£ng m√†u phong ph√∫ v√† ƒëa d·∫°ng")
            else:
                analysis_parts.append("v·ªõi t√¥ng m√†u h√†i h√≤a v√† c√¢n b·∫±ng")
        
        # Object analysis
        if high_level.get('objects'):
            objects = high_level['objects']
            if len(objects) > 5:
                analysis_parts.append("Composition ph·ª©c t·∫°p v·ªõi nhi·ªÅu y·∫øu t·ªë")
            else:
                analysis_parts.append("Composition ƒë∆°n gi·∫£n, t·∫≠p trung")
        
        # Quality assessment
        if quality.get('quality_score'):
            score = quality['quality_score']
            if score > 80:
                analysis_parts.append("Ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ xu·∫•t s·∫Øc")
            elif score > 60:
                analysis_parts.append("Ch·∫•t l∆∞·ª£ng t·ªët")
            else:
                analysis_parts.append("C·∫ßn c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ")
        
        # Professional recommendations
        recommendations = []
        if quality.get('brightness', 50) < 40:
            recommendations.append("tƒÉng ƒë·ªô s√°ng")
        if quality.get('contrast', 50) < 40:
            recommendations.append("c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n")
        if quality.get('sharpness', 50) < 60:
            recommendations.append("tƒÉng ƒë·ªô s·∫Øc n√©t")
        
        if recommendations:
            analysis_parts.append(f"G·ª£i √Ω c·∫£i thi·ªán: {', '.join(recommendations)}")
        
        # Combine analysis
        if analysis_parts:
            analysis = '. '.join(analysis_parts) + '.'
        else:
            analysis = "ƒê√¢y l√† m·ªôt b·ª©c ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng t·ªët v·ªõi composition c√¢n ƒë·ªëi. K·ªπ thu·∫≠t th·ª±c hi·ªán ·ªïn ƒë·ªãnh, th·ªÉ hi·ªán ƒë∆∞·ª£c √Ω t∆∞·ªüng c·ªßa t√°c gi·∫£. C√≥ th·ªÉ c·∫£i thi·ªán th√™m v·ªÅ ƒë·ªô t∆∞∆°ng ph·∫£n v√† m√†u s·∫Øc ƒë·ªÉ tƒÉng t√≠nh thu h√∫t."
        
        return {
            'professional_analysis': analysis,
            'model_used': 'Professional Fallback Analysis',
            'analysis_framework': 'rule_based_professional',
            'note': 'Ph√¢n t√≠ch d·ª±a tr√™n ti√™u ch√≠ k·ªπ thu·∫≠t chuy√™n nghi·ªáp'
        }
